{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c040716",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from hyperopt import STATUS_OK,Trials,fmin,hp,tpe\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import mlflow\n",
    "from mlflow.models import infer_signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70cc4ece",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "fixed acidity",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "volatile acidity",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "citric acid",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "residual sugar",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "chlorides",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "free sulfur dioxide",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "total sulfur dioxide",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "density",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "pH",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "sulphates",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "alcohol",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "quality",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "abf64296-9c2e-4e3d-add9-e711d97adee1",
       "rows": [
        [
         "0",
         "7.0",
         "0.27",
         "0.36",
         "20.7",
         "0.045",
         "45.0",
         "170.0",
         "1.001",
         "3.0",
         "0.45",
         "8.8",
         "6"
        ],
        [
         "1",
         "6.3",
         "0.3",
         "0.34",
         "1.6",
         "0.049",
         "14.0",
         "132.0",
         "0.994",
         "3.3",
         "0.49",
         "9.5",
         "6"
        ],
        [
         "2",
         "8.1",
         "0.28",
         "0.4",
         "6.9",
         "0.05",
         "30.0",
         "97.0",
         "0.9951",
         "3.26",
         "0.44",
         "10.1",
         "6"
        ],
        [
         "3",
         "7.2",
         "0.23",
         "0.32",
         "8.5",
         "0.058",
         "47.0",
         "186.0",
         "0.9956",
         "3.19",
         "0.4",
         "9.9",
         "6"
        ],
        [
         "4",
         "7.2",
         "0.23",
         "0.32",
         "8.5",
         "0.058",
         "47.0",
         "186.0",
         "0.9956",
         "3.19",
         "0.4",
         "9.9",
         "6"
        ],
        [
         "5",
         "8.1",
         "0.28",
         "0.4",
         "6.9",
         "0.05",
         "30.0",
         "97.0",
         "0.9951",
         "3.26",
         "0.44",
         "10.1",
         "6"
        ],
        [
         "6",
         "6.2",
         "0.32",
         "0.16",
         "7.0",
         "0.045",
         "30.0",
         "136.0",
         "0.9949",
         "3.18",
         "0.47",
         "9.6",
         "6"
        ],
        [
         "7",
         "7.0",
         "0.27",
         "0.36",
         "20.7",
         "0.045",
         "45.0",
         "170.0",
         "1.001",
         "3.0",
         "0.45",
         "8.8",
         "6"
        ],
        [
         "8",
         "6.3",
         "0.3",
         "0.34",
         "1.6",
         "0.049",
         "14.0",
         "132.0",
         "0.994",
         "3.3",
         "0.49",
         "9.5",
         "6"
        ],
        [
         "9",
         "8.1",
         "0.22",
         "0.43",
         "1.5",
         "0.044",
         "28.0",
         "129.0",
         "0.9938",
         "3.22",
         "0.45",
         "11.0",
         "6"
        ],
        [
         "10",
         "8.1",
         "0.27",
         "0.41",
         "1.45",
         "0.033",
         "11.0",
         "63.0",
         "0.9908",
         "2.99",
         "0.56",
         "12.0",
         "5"
        ],
        [
         "11",
         "8.6",
         "0.23",
         "0.4",
         "4.2",
         "0.035",
         "17.0",
         "109.0",
         "0.9947",
         "3.14",
         "0.53",
         "9.7",
         "5"
        ],
        [
         "12",
         "7.9",
         "0.18",
         "0.37",
         "1.2",
         "0.04",
         "16.0",
         "75.0",
         "0.992",
         "3.18",
         "0.63",
         "10.8",
         "5"
        ],
        [
         "13",
         "6.6",
         "0.16",
         "0.4",
         "1.5",
         "0.044",
         "48.0",
         "143.0",
         "0.9912",
         "3.54",
         "0.52",
         "12.4",
         "7"
        ],
        [
         "14",
         "8.3",
         "0.42",
         "0.62",
         "19.25",
         "0.04",
         "41.0",
         "172.0",
         "1.0002",
         "2.98",
         "0.67",
         "9.7",
         "5"
        ],
        [
         "15",
         "6.6",
         "0.17",
         "0.38",
         "1.5",
         "0.032",
         "28.0",
         "112.0",
         "0.9914",
         "3.25",
         "0.55",
         "11.4",
         "7"
        ],
        [
         "16",
         "6.3",
         "0.48",
         "0.04",
         "1.1",
         "0.046",
         "30.0",
         "99.0",
         "0.9928",
         "3.24",
         "0.36",
         "9.6",
         "6"
        ],
        [
         "17",
         "6.2",
         "0.66",
         "0.48",
         "1.2",
         "0.029",
         "29.0",
         "75.0",
         "0.9892",
         "3.33",
         "0.39",
         "12.8",
         "8"
        ],
        [
         "18",
         "7.4",
         "0.34",
         "0.42",
         "1.1",
         "0.033",
         "17.0",
         "171.0",
         "0.9917",
         "3.12",
         "0.53",
         "11.3",
         "6"
        ],
        [
         "19",
         "6.5",
         "0.31",
         "0.14",
         "7.5",
         "0.044",
         "34.0",
         "133.0",
         "0.9955",
         "3.22",
         "0.5",
         "9.5",
         "5"
        ],
        [
         "20",
         "6.2",
         "0.66",
         "0.48",
         "1.2",
         "0.029",
         "29.0",
         "75.0",
         "0.9892",
         "3.33",
         "0.39",
         "12.8",
         "8"
        ],
        [
         "21",
         "6.4",
         "0.31",
         "0.38",
         "2.9",
         "0.038",
         "19.0",
         "102.0",
         "0.9912",
         "3.17",
         "0.35",
         "11.0",
         "7"
        ],
        [
         "22",
         "6.8",
         "0.26",
         "0.42",
         "1.7",
         "0.049",
         "41.0",
         "122.0",
         "0.993",
         "3.47",
         "0.48",
         "10.5",
         "8"
        ],
        [
         "23",
         "7.6",
         "0.67",
         "0.14",
         "1.5",
         "0.074",
         "25.0",
         "168.0",
         "0.9937",
         "3.05",
         "0.51",
         "9.3",
         "5"
        ],
        [
         "24",
         "6.6",
         "0.27",
         "0.41",
         "1.3",
         "0.052",
         "16.0",
         "142.0",
         "0.9951",
         "3.42",
         "0.47",
         "10.0",
         "6"
        ],
        [
         "25",
         "7.0",
         "0.25",
         "0.32",
         "9.0",
         "0.046",
         "56.0",
         "245.0",
         "0.9955",
         "3.25",
         "0.5",
         "10.4",
         "6"
        ],
        [
         "26",
         "6.9",
         "0.24",
         "0.35",
         "1.0",
         "0.052",
         "35.0",
         "146.0",
         "0.993",
         "3.45",
         "0.44",
         "10.0",
         "6"
        ],
        [
         "27",
         "7.0",
         "0.28",
         "0.39",
         "8.7",
         "0.051",
         "32.0",
         "141.0",
         "0.9961",
         "3.38",
         "0.53",
         "10.5",
         "6"
        ],
        [
         "28",
         "7.4",
         "0.27",
         "0.48",
         "1.1",
         "0.047",
         "17.0",
         "132.0",
         "0.9914",
         "3.19",
         "0.49",
         "11.6",
         "6"
        ],
        [
         "29",
         "7.2",
         "0.32",
         "0.36",
         "2.0",
         "0.033",
         "37.0",
         "114.0",
         "0.9906",
         "3.1",
         "0.71",
         "12.3",
         "7"
        ],
        [
         "30",
         "8.5",
         "0.24",
         "0.39",
         "10.4",
         "0.044",
         "20.0",
         "142.0",
         "0.9974",
         "3.2",
         "0.53",
         "10.0",
         "6"
        ],
        [
         "31",
         "8.3",
         "0.14",
         "0.34",
         "1.1",
         "0.042",
         "7.0",
         "47.0",
         "0.9934",
         "3.47",
         "0.4",
         "10.2",
         "6"
        ],
        [
         "32",
         "7.4",
         "0.25",
         "0.36",
         "2.05",
         "0.05",
         "31.0",
         "100.0",
         "0.992",
         "3.19",
         "0.44",
         "10.8",
         "6"
        ],
        [
         "33",
         "6.2",
         "0.12",
         "0.34",
         "1.5",
         "0.045",
         "43.0",
         "117.0",
         "0.9939",
         "3.42",
         "0.51",
         "9.0",
         "6"
        ],
        [
         "34",
         "5.8",
         "0.27",
         "0.2",
         "14.95",
         "0.044",
         "22.0",
         "179.0",
         "0.9962",
         "3.37",
         "0.37",
         "10.2",
         "5"
        ],
        [
         "35",
         "7.3",
         "0.28",
         "0.43",
         "1.7",
         "0.08",
         "21.0",
         "123.0",
         "0.9905",
         "3.19",
         "0.42",
         "12.8",
         "5"
        ],
        [
         "36",
         "6.5",
         "0.39",
         "0.23",
         "5.4",
         "0.051",
         "25.0",
         "149.0",
         "0.9934",
         "3.24",
         "0.35",
         "10.0",
         "5"
        ],
        [
         "37",
         "7.0",
         "0.33",
         "0.32",
         "1.2",
         "0.053",
         "38.0",
         "138.0",
         "0.9906",
         "3.13",
         "0.28",
         "11.2",
         "6"
        ],
        [
         "38",
         "7.3",
         "0.24",
         "0.39",
         "17.95",
         "0.057",
         "45.0",
         "149.0",
         "0.9999",
         "3.21",
         "0.36",
         "8.6",
         "5"
        ],
        [
         "39",
         "7.3",
         "0.24",
         "0.39",
         "17.95",
         "0.057",
         "45.0",
         "149.0",
         "0.9999",
         "3.21",
         "0.36",
         "8.6",
         "5"
        ],
        [
         "40",
         "6.7",
         "0.23",
         "0.39",
         "2.5",
         "0.172",
         "63.0",
         "158.0",
         "0.9937",
         "3.11",
         "0.36",
         "9.4",
         "6"
        ],
        [
         "41",
         "6.7",
         "0.24",
         "0.39",
         "2.9",
         "0.173",
         "63.0",
         "157.0",
         "0.9937",
         "3.1",
         "0.34",
         "9.4",
         "6"
        ],
        [
         "42",
         "7.0",
         "0.31",
         "0.26",
         "7.4",
         "0.069",
         "28.0",
         "160.0",
         "0.9954",
         "3.13",
         "0.46",
         "9.8",
         "6"
        ],
        [
         "43",
         "6.6",
         "0.24",
         "0.27",
         "1.4",
         "0.057",
         "33.0",
         "152.0",
         "0.9934",
         "3.22",
         "0.56",
         "9.5",
         "6"
        ],
        [
         "44",
         "6.7",
         "0.23",
         "0.26",
         "1.4",
         "0.06",
         "33.0",
         "154.0",
         "0.9934",
         "3.24",
         "0.56",
         "9.5",
         "6"
        ],
        [
         "45",
         "7.4",
         "0.18",
         "0.31",
         "1.4",
         "0.058",
         "38.0",
         "167.0",
         "0.9931",
         "3.16",
         "0.53",
         "10.0",
         "7"
        ],
        [
         "46",
         "6.2",
         "0.45",
         "0.26",
         "4.4",
         "0.063",
         "63.0",
         "206.0",
         "0.994",
         "3.27",
         "0.52",
         "9.8",
         "4"
        ],
        [
         "47",
         "6.2",
         "0.46",
         "0.25",
         "4.4",
         "0.066",
         "62.0",
         "207.0",
         "0.9939",
         "3.25",
         "0.52",
         "9.8",
         "5"
        ],
        [
         "48",
         "7.0",
         "0.31",
         "0.26",
         "7.4",
         "0.069",
         "28.0",
         "160.0",
         "0.9954",
         "3.13",
         "0.46",
         "9.8",
         "6"
        ],
        [
         "49",
         "6.9",
         "0.19",
         "0.35",
         "5.0",
         "0.067",
         "32.0",
         "150.0",
         "0.995",
         "3.36",
         "0.48",
         "9.8",
         "5"
        ]
       ],
       "shape": {
        "columns": 12,
        "rows": 4898
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.00100</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.99400</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.99510</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.99560</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.99560</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4893</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.039</td>\n",
       "      <td>24.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.99114</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.50</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4894</th>\n",
       "      <td>6.6</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.36</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.047</td>\n",
       "      <td>57.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4895</th>\n",
       "      <td>6.5</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.041</td>\n",
       "      <td>30.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.99254</td>\n",
       "      <td>2.99</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4896</th>\n",
       "      <td>5.5</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.022</td>\n",
       "      <td>20.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.98869</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.38</td>\n",
       "      <td>12.8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4897</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.020</td>\n",
       "      <td>22.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.98941</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.32</td>\n",
       "      <td>11.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4898 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               7.0              0.27         0.36            20.7      0.045   \n",
       "1               6.3              0.30         0.34             1.6      0.049   \n",
       "2               8.1              0.28         0.40             6.9      0.050   \n",
       "3               7.2              0.23         0.32             8.5      0.058   \n",
       "4               7.2              0.23         0.32             8.5      0.058   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "4893            6.2              0.21         0.29             1.6      0.039   \n",
       "4894            6.6              0.32         0.36             8.0      0.047   \n",
       "4895            6.5              0.24         0.19             1.2      0.041   \n",
       "4896            5.5              0.29         0.30             1.1      0.022   \n",
       "4897            6.0              0.21         0.38             0.8      0.020   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                    45.0                 170.0  1.00100  3.00       0.45   \n",
       "1                    14.0                 132.0  0.99400  3.30       0.49   \n",
       "2                    30.0                  97.0  0.99510  3.26       0.44   \n",
       "3                    47.0                 186.0  0.99560  3.19       0.40   \n",
       "4                    47.0                 186.0  0.99560  3.19       0.40   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "4893                 24.0                  92.0  0.99114  3.27       0.50   \n",
       "4894                 57.0                 168.0  0.99490  3.15       0.46   \n",
       "4895                 30.0                 111.0  0.99254  2.99       0.46   \n",
       "4896                 20.0                 110.0  0.98869  3.34       0.38   \n",
       "4897                 22.0                  98.0  0.98941  3.26       0.32   \n",
       "\n",
       "      alcohol  quality  \n",
       "0         8.8        6  \n",
       "1         9.5        6  \n",
       "2        10.1        6  \n",
       "3         9.9        6  \n",
       "4         9.9        6  \n",
       "...       ...      ...  \n",
       "4893     11.2        6  \n",
       "4894      9.6        5  \n",
       "4895      9.4        6  \n",
       "4896     12.8        7  \n",
       "4897     11.8        6  \n",
       "\n",
       "[4898 rows x 12 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\n",
    "    \"https://raw.githubusercontent.com/mlflow/mlflow/master/tests/datasets/winequality-white.csv\",sep=\";\"\n",
    "\n",
    ")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3658f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "train,test = train_test_split(data,test_size=0.25,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8bff1f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train.drop(columns=\"quality\").values\n",
    "train_y = train[\"quality\"].values.ravel() # ravel 2d array to 1d array\n",
    "\n",
    "#test\n",
    "\n",
    "test_x = test.drop(columns=\"quality\").values\n",
    "test_y = test[\"quality\"].values.ravel()\n",
    "\n",
    "# validation\n",
    "\n",
    "train_x,valid_x,train_y,valid_y = train_test_split(train_x,train_y,test_size=0.20,random_state=42)\n",
    "\n",
    "signature = infer_signature(train_x,train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b104077",
   "metadata": {},
   "source": [
    "# ANN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "897c3197",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow.metrics\n",
    "import mlflow.pytorch\n",
    "import mlflow.tensorflow\n",
    "\n",
    "\n",
    "def train_model(params,epochs,train_x,train_y,valid_x,valid_y,test_x,test_y):\n",
    "    # nomalize\n",
    "    mean = np.mean(train_x,axis=0)\n",
    "    variance = np.var(train_x,axis=0)\n",
    "    \n",
    "    model = keras.Sequential(\n",
    "        [\n",
    "            keras.Input([train_x.shape[1]]),\n",
    "            keras.layers.Normalization(mean=mean,variance=variance),\n",
    "            keras.layers.Dense(32,activation='relu'),\n",
    "            keras.layers.Dense(1)\n",
    "        ]\n",
    "    )\n",
    "    # compile the model\n",
    "    model.compile(optimizer=keras.optimizers.SGD(\n",
    "                 learning_rate=params[\"lr\"],momentum=params[\"momentum\"]\n",
    "    ),\n",
    "        loss=\"mean_squared_error\",\n",
    "        metrics=[keras.metrics.RootMeanSquaredError()]\n",
    "    )\n",
    "    \n",
    "    ## Train the model and track lr and momentum with MLFLOW\n",
    "    with mlflow.start_run(nested=True):\n",
    "        model.fit(train_x,train_y,validation_data=(valid_x,valid_y),\n",
    "                  epochs=epochs,\n",
    "                  batch_size=32)\n",
    "        ## Evaluate\n",
    "        eval_result = model.evaluate(valid_x,valid_y,batch_size=32)\n",
    "        \n",
    "        eval_rmse=eval_result[1]\n",
    "        mlflow.log_params(params)\n",
    "        mlflow.log_metric(\"eval_rmse\",eval_rmse)\n",
    "        # Log model\n",
    "        mlflow.tensorflow.log_model(model,\"model\",signature=signature)\n",
    "        \n",
    "        return {\"loss\":eval_rmse,\"status\":STATUS_OK,\"model\":model}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d835f2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    # Mlflow will track the parameters and results for each run\n",
    "    result = train_model(\n",
    "        params,\n",
    "        epochs=3,\n",
    "        train_x=train_x,\n",
    "        train_y=train_y,\n",
    "        valid_x=valid_x,\n",
    "        valid_y=valid_y,\n",
    "        test_x=test_x,\n",
    "        test_y=test_y,\n",
    "    )\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a5e86f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "space={\n",
    "    \"lr\":hp.loguniform(\"lt\",np.log(1e-5),np.log(1e-1)),\n",
    "    \"momentum\":hp.uniform(\"momentum\",0.0,1.0)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1fb66f98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3                                            \n",
      "\n",
      "\u001b[1m 1/92\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m25s\u001b[0m 278ms/step - loss: 37.8391 - root_mean_squared_error: 6.1513\n",
      "\u001b[1m45/92\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 34.8397 - root_mean_squared_error: 5.8971   \n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 30.4055 - root_mean_squared_error: 5.4956 - val_loss: 11.6394 - val_root_mean_squared_error: 3.4117\n",
      "\n",
      "Epoch 2/3                                            \n",
      "\n",
      "\u001b[1m 1/92\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 13.7437 - root_mean_squared_error: 3.7073\n",
      "\u001b[1m54/92\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 945us/step - loss: 9.5939 - root_mean_squared_error: 3.0925\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.6210 - root_mean_squared_error: 2.9262 - val_loss: 4.0471 - val_root_mean_squared_error: 2.0117\n",
      "\n",
      "Epoch 3/3                                            \n",
      "\n",
      "\u001b[1m 1/92\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 2.4342 - root_mean_squared_error: 1.5602\n",
      "\u001b[1m53/92\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 975us/step - loss: 3.6088 - root_mean_squared_error: 1.8988\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.4371 - root_mean_squared_error: 1.8526 - val_loss: 2.7970 - val_root_mean_squared_error: 1.6724\n",
      "\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 3.3771 - root_mean_squared_error: 1.8377\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.7978 - root_mean_squared_error: 1.6719 \n",
      "\n",
      "Epoch 1/3                                                                     \n",
      "\n",
      "\u001b[1m 1/92\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m43s\u001b[0m 476ms/step - loss: 39.1368 - root_mean_squared_error: 6.2559\n",
      "\u001b[1m25/92\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19.6169 - root_mean_squared_error: 4.3387   \n",
      "\u001b[1m49/92\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 13.7840 - root_mean_squared_error: 3.5701\n",
      "\u001b[1m70/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 11.2685 - root_mean_squared_error: 3.1957\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 9.5568 - root_mean_squared_error: 2.9209 - val_loss: 1.3801 - val_root_mean_squared_error: 1.1748\n",
      "\n",
      "Epoch 2/3                                                                     \n",
      "\n",
      "\u001b[1m 1/92\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - loss: 0.7978 - root_mean_squared_error: 0.8932\n",
      "\u001b[1m30/92\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.3398 - root_mean_squared_error: 1.1558 \n",
      "\u001b[1m57/92\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.2963 - root_mean_squared_error: 1.1375\n",
      "\u001b[1m82/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.2515 - root_mean_squared_error: 1.1175\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.2338 - root_mean_squared_error: 1.1095 - val_loss: 0.9832 - val_root_mean_squared_error: 0.9915\n",
      "\n",
      "Epoch 3/3                                                                     \n",
      "\n",
      "\u001b[1m 1/92\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 2.1161 - root_mean_squared_error: 1.4547\n",
      "\u001b[1m27/92\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.1033 - root_mean_squared_error: 1.0459 \n",
      "\u001b[1m62/92\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0130 - root_mean_squared_error: 1.0036\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9573 - root_mean_squared_error: 0.9757 - val_loss: 0.7927 - val_root_mean_squared_error: 0.8904\n",
      "\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.6680 - root_mean_squared_error: 0.8173\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8133 - root_mean_squared_error: 0.9015 \n",
      "\n",
      "Epoch 1/3                                                                      \n",
      "\n",
      "\u001b[1m 1/92\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m24s\u001b[0m 274ms/step - loss: 31.3267 - root_mean_squared_error: 5.5970\n",
      "\u001b[1m38/92\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 28.5639 - root_mean_squared_error: 5.3438   \n",
      "\u001b[1m83/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 27.1944 - root_mean_squared_error: 5.2129\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 26.9264 - root_mean_squared_error: 5.1868 - val_loss: 20.9230 - val_root_mean_squared_error: 4.5742\n",
      "\n",
      "Epoch 2/3                                                                      \n",
      "\n",
      "\u001b[1m 1/92\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 21.8384 - root_mean_squared_error: 4.6732\n",
      "\u001b[1m57/92\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 908us/step - loss: 19.9215 - root_mean_squared_error: 4.4631\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19.4192 - root_mean_squared_error: 4.4059 - val_loss: 15.4472 - val_root_mean_squared_error: 3.9303\n",
      "\n",
      "Epoch 3/3                                                                      \n",
      "\n",
      "\u001b[1m 1/92\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 14.2194 - root_mean_squared_error: 3.7709\n",
      "\u001b[1m53/92\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 965us/step - loss: 15.0531 - root_mean_squared_error: 3.8796\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 14.5658 - root_mean_squared_error: 3.8155 - val_loss: 11.3753 - val_root_mean_squared_error: 3.3727\n",
      "\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 10.5396 - root_mean_squared_error: 3.2465\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 11.1028 - root_mean_squared_error: 3.3319 \n",
      "\n",
      "Epoch 1/3                                                                      \n",
      "\n",
      "\u001b[1m 1/92\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m38s\u001b[0m 428ms/step - loss: 34.0745 - root_mean_squared_error: 5.8373\n",
      "\u001b[1m44/92\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.1822 - root_mean_squared_error: 2.5093    \n",
      "\u001b[1m87/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.7329 - root_mean_squared_error: 2.0050\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.5418 - root_mean_squared_error: 1.9615 - val_loss: 0.6800 - val_root_mean_squared_error: 0.8246\n",
      "\n",
      "Epoch 2/3                                                                      \n",
      "\n",
      "\u001b[1m 1/92\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.6838 - root_mean_squared_error: 0.8269\n",
      "\u001b[1m40/92\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6288 - root_mean_squared_error: 0.7927 \n",
      "\u001b[1m77/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6144 - root_mean_squared_error: 0.7836\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6120 - root_mean_squared_error: 0.7821 - val_loss: 0.5803 - val_root_mean_squared_error: 0.7618\n",
      "\n",
      "Epoch 3/3                                                                      \n",
      "\n",
      "\u001b[1m 1/92\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 0.6163 - root_mean_squared_error: 0.7850\n",
      "\u001b[1m33/92\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6332 - root_mean_squared_error: 0.7956 \n",
      "\u001b[1m61/92\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6226 - root_mean_squared_error: 0.7889\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6128 - root_mean_squared_error: 0.7826 - val_loss: 0.5497 - val_root_mean_squared_error: 0.7414\n",
      "\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.4230 - root_mean_squared_error: 0.6504\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5435 - root_mean_squared_error: 0.7369 \n",
      "\n",
      "100%|██████████| 4/4 [00:41<00:00, 10.36s/trial, best loss: 0.7413870096206665]\n",
      "Best parameters: {'lt': np.float64(0.02710212388400296), 'momentum': np.float64(0.7157700304990878)}\n",
      "Best eval rmse: 0.7413870096206665\n"
     ]
    }
   ],
   "source": [
    "import mlflow.tensorflow\n",
    "\n",
    "\n",
    "mlflow.set_experiment(\"/wine-quality\")\n",
    "with mlflow.start_run():\n",
    "    trials = Trials()\n",
    "    best=fmin(\n",
    "        fn=objective,\n",
    "        space=space,\n",
    "        algo=tpe.suggest,\n",
    "        max_evals=4,\n",
    "        trials=trials,\n",
    "    )\n",
    "    best_run = sorted(trials.results,key=lambda x:x[\"loss\"])[0]\n",
    "    \n",
    "    mlflow.log_params(best)\n",
    "    mlflow.log_metric(\"eval_rmse\",best_run[\"loss\"])\n",
    "    mlflow.tensorflow.log_model(best_run[\"model\"],\"model\",signature=signature)\n",
    "    \n",
    "    print(f\"Best parameters: {best}\")\n",
    "    print(f\"Best eval rmse: {best_run['loss']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc72b772",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
